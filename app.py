import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import json
import os

# ==============================
# CONFIG
BASE_URL = "https://masothue.com"
HISTORY_FILE = "history.json"

# ==============================
# FILE HANDLING
def save_json_file(filename, data):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_json_file(filename):
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

# ==============================
# CRAWLER
def fetch_new_companies(pages=5):
    """
    L·∫•y danh s√°ch DN m·ªõi th√†nh l·∫≠p (5 trang)
    """
    rows = []
    for page in range(1, pages + 1):
        url = f"{BASE_URL}/tra-cuu-ma-so-thue-doanh-nghiep-moi-thanh-lap?page={page}"
        try:
            resp = requests.get(url, timeout=10)
            soup = BeautifulSoup(resp.text, "html.parser")
            for li in soup.select(".tax-listing li"):
                name_tag = li.find("a", class_="tax-name")
                addr_tag = li.find("span", class_="address")
                if name_tag and addr_tag:
                    name = name_tag.get_text(strip=True)
                    link = BASE_URL + name_tag["href"]
                    address = addr_tag.get_text(strip=True)
                    rows.append({
                        "T√™n doanh nghi·ªáp": name,
                        "ƒê·ªãa ch·ªâ": address,
                        "Link": link
                    })
        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói khi t·∫£i trang {page}: {e}")
    return pd.DataFrame(rows)

# ==============================
# UI
st.title("üìä Tra c·ª©u doanh nghi·ªáp m·ªõi th√†nh l·∫≠p")

# N√∫t tra c·ª©u
if st.button("üîç Tra c·ª©u"):
    st.info("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu (5 trang)...")
    df = fetch_new_companies(pages=5)

    if not df.empty:
        st.success(f"‚úÖ ƒê√£ t√¨m th·∫•y {len(df)} doanh nghi·ªáp m·ªõi.")
        # L·ªçc t·ªânh
        provinces = ["T·∫•t c·∫£"] + sorted(list(set([addr.split(",")[-1].strip() for addr in df["ƒê·ªãa ch·ªâ"]])))
        selected_province = st.selectbox("üìç L·ªçc theo t·ªânh/TP", provinces)

        if selected_province != "T·∫•t c·∫£":
            filtered_df = df[df["ƒê·ªãa ch·ªâ"].str.contains(selected_province, case=False)]
        else:
            filtered_df = df

        st.dataframe(filtered_df, use_container_width=True)

        # L∆∞u l·ªãch s·ª≠
        history = load_json_file(HISTORY_FILE)
        history.insert(0, {
            "T√¨m ki·∫øm": "T·∫•t c·∫£ DN m·ªõi",
            "S·ªë l∆∞·ª£ng": len(df)
        })
        save_json_file(HISTORY_FILE, history[:10])  # L∆∞u t·ªëi ƒëa 10 d√≤ng

    else:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu.")

# Hi·ªÉn th·ªã l·ªãch s·ª≠
st.subheader("‚è≥ L·ªãch s·ª≠ t√¨m ki·∫øm")
history = load_json_file(HISTORY_FILE)
if history:
    st.table(pd.DataFrame(history))
else:
    st.info("üì≠ Ch∆∞a c√≥ l·ªãch s·ª≠.")
